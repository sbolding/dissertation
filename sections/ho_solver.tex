
\chapter{\uppercase {The Exponentially-Convergent Monte Carlo High-Order Solver}}
\label{chp:ho}

The time-discretized transport equation to be solved by the HO solver is
\begin{equation}\label{eq:ho_base}
\mu \pderiv{I^{n+1,k+1/2}}{x} + \left(\sigma_t^k + \frac{1}{c \Delta t }\right)
I^{n+1,k+1/2}
= \frac{\sigma_s}{2} \phi^{n+1,k} +\frac{1}{2} \left(\sigma_a^k a c T^4
\right)^{n+1,k} + \frac{\tilde I^n}{c\Delta t} 
\end{equation}
where the superscript $k$ represents the outer HOLO iteration index.  Here, $k+1/2$ denotes the
HO solve within outer HOLO iteration $k$, whereas $k$ and $k+1$ represent successive LO
solves. The sources at $k$ in Eq.~\eqref{eq:ho_base} are estimated by the previous LO
solution. Temperature-dependent cross sections are
evaluated at $T^{n+1,k}$.  As all sources on the right side of the equation are known,
this defines a fixed-source, pure absorber transport problem.  The above transport equation has
the same form as a steady-state neutronics problem.  We will solve
this transport problem using the ECMC method. 

In the remainder of this chapter, an overview of
the ECMC solution method applied in this work is given.  First, the LDFE trial
space used by the ECMC algorithm is detailed.  Then, the ECMC algorithm is
developed, followed by more specific sampling and tracking details.  

\section{Implementation of LDFE $x$-$\mu$ Trial Space}

To form the algorithm, a trial-space representation for the intensity is necessary.  The ECMC solver uses a finite element representation in space and angle. On the
interior of the cell with the $i$-th spatial index and $j$-th angular index, the linear representation is defined as
\begin{equation}\label{eq:ld_intens}
    \tilde I(x,\mu) = I_{a,ij} + \frac{2}{h_i}I_{x,ij}\left(x-x_i\right) +
    \frac{2}{h_j}I_{\mu,ij}\left(\mu-\mu_j\right), \quad \quad (x,\mu) \in
    \mathcal{D}_{ij},
\end{equation}
where $\mathcal{D}_{ij}: x_\il \leq  x \leq  x_\ir \times \mu_\jl \leq \mu \leq \mu_\jr$
is a rectangular cell in space and angle.
The spatial cell width is $h_i$, the angular width is
$h_j$, the center of the cell is $(x_i,\mu_j)$, and
\begin{align}\label{eq:Imoms}
    I_{a,ij} &= \frac{1}{h_i h_j} \iint\limits_{\mathcal{D}_{ij}} I(x,\mu)\, \dd x \dd \mu \\
    I_{x,ij} &= \frac{6}{h_ih_j}\iint\limits_{\mathcal{D}_{ij}} \left(\frac{x - x_i}{h_{i}}\right)
    I(x,\mu)\, \dd x \dd \mu \\ \label{eq:Imoms2}
    I_{\mu,ij} &= \frac{6}{h_ih_j}\iint\limits_{\mathcal{D}_{ij}}
    \left(\frac{\mu - \mu_j}{h_{j}}\right)
    I(x,\mu)\, \dd x \dd \mu,
\end{align} 
where $I_a$ is the cell-averaged intensity, and $I_\mu$ and $I_x$ define the first
moment in $\mu$ and $x$ of the intensity, respectively.  The streaming term requires
definition of $I(x,\mu)$ on faces.  Standard upwinding in space is
used to define $I(\mu)$ on incoming faces, e.g., for an unrefined mesh,
\begin{equation}\label{eq:left_uw}
    \tilde{I}_{ij}(x_{i-1/2},\mu) = \left \{ \begin{array}{cl}
        I_{a,i-1,j}+I_{x,i-1,j}+\frac{2}{h_j}I_{\mu,i-1,j}\left(\mu-\mu_j\right) & 0 \leq \mu_{j-1/2} \leq \mu \leq \mu_{j+1/2} \\ 
I_{a,ij}-I_{x,ij}+\frac{2}{h_j}I_{\mu,ij}\left(\mu-\mu_j\right) &   \mu_{j-1/2} \leq \mu \leq \mu_{j+1/2} \leq 0
\end{array} \right.
\end{equation}
and
\begin{equation}\label{eq:right_uw}
    \tilde{I}_{ij}(x_{i+1/2},\mu) = \left \{ \begin{array}{cl}
I_{a,ij}+I_{x,ij}+\frac{2}{h_j}I_{\mu,ij}\left(\mu-\mu_j\right)
         & 0 \leq \mu_{j-1/2} \leq \mu \leq \mu_{j+1/2} \\ 
I_{a,i+1,j}-I_{x,i+1,j}+\frac{2}{h_j}I_{\mu,i+1,j}\left(\mu-\mu_j\right)
&   \mu_{j-1/2} \leq \mu \leq \mu_{j+1/2} \leq 0
\end{array} \right. ,
\end{equation}
for all $i$ and $j$ on the interior of the domain.  For all simulations in this work,
boundary conditions are provided as a specified isotropic intensity. Thus, the value of
$I_{1j}(x_1/2,\mu)$ is a constant, for all $j$.

\section{The ECMC Algorithm}
\label{sec:ecmc}

The ECMC method is an iterative residual MC method. 
In operator notation, Eq.~\eqref{eq:ho_base} can be written as
\begin{equation}\label{te_oper}
\B L^k I^{n+1,k+1/2}  = q^{k}
\end{equation}
where $I^{n+1,k+1/2}$ is the transport solution of the angular intensity based on the
$k$-th LO estimate of $q^k$.
The linear operator $\B L^k$ is the \emph{continuous} streaming plus
removal operator, given by the left-hand
side of Eq.~\eqref{eq:ho_base}, i.e.,
\begin{equation}
    \B L^k(\cdot) = \left[\mu \pderiv{}{x} + \left(\sigma_t^k + \frac{1}{c \Delta t
    }\right)\right] \left(\cdot\right)
\end{equation}
We will use superscript $(m)$ to indicated the $m$-th inner HO iteration.  The LDFE
representation of the $m$-th
approximate solution to Eq.~\eqref{te_oper} is denoted
$\tilde{I}^{n+1,(m)}(x,\mu)$.    
The associated residual is defined as $r^{(m)} = q - \B L^k\tilde{I}^{n+1,(m)}.$ 
Explicitly, the residual at iteration $m$ is
\begin{multline}\label{eq:resid}
r^{(m),k+1/2} = \frac{\sigma_s}{2} \phi^{n+1,k} +\frac{1}{2} \left(\sigma_a a c T^4
\right)^{n+1,k} + \frac{\tilde{I}^n}{c \Delta t } \\ -
\left(\mu \pderiv{\tilde{I}^{n+1,k+1/2}}{x} +
\left(\sigma_t^k + \frac{1}{c \Delta t }\right) \tilde{I}^{n+1,k+1/2}\right)^{(m)}
\end{multline}
where the $k$ terms have a LDFE representation in space on the coarsest mesh and are not recalculated at any point during
the HO solve.  The LDFE functional form of $\tilde{I}^n$ is defined from the final HO
solution of the previous time step.  The HOLO iteration indices are suppressed for the
remainder of this chapter because the LO-estimated $q^{k}$ and $\B L^{k}$
\emph{remain constant for the entire HO solve}.

Addition of $\B L I^{n+1} - q=0$ to the Eq.~\eqref{eq:resid}, i.e., the residual equation,
and manipulation of the result yields the error equation
\begin{equation}\label{eq:err_eq}
    \B L (I^{n+1} - \tilde{I}^{n+1,(m)}) = \B L {\epsilon}^{(m)} = r^{(m)}
\end{equation}
where $I^{n+1}$ is the exact solution\footnote{For clarity, in this chapter the exact solution is the
    exact solution to the transport problem defined by Eq.~\eqref{eq:ho_base}, not to the
continuous equations that are trying to be solved.}  to the problem defined by Eq.~\eqref{eq:ho_base} and
${\epsilon}^{(m)}$ is the true error in the approximate solution $\tilde{I}^{n+1,(m)}$. 
In the above equation, the incoming error is treated with a vacuum boundary condition.  The
residual source incorporates the incident intensity at boundaries through
the face source.
The $\B L$ operator in the above equation is inverted with the MC method, which
statistically estimates an LDFE projection of the error in $\tilde{I}^{n+1,(m)}$, i.e., 
\begin{equation}\label{eq:mc_err}
\tilde{\epsilon}^{(m)} = \B L^{-1} r^{(m)}
\end{equation}
where $\B L^{-1}$ is the Monte Carlo inversion of the streaming and removal operator.  
This inversion is strictly a standard Monte Carlo simulation; particle histories are
tracked and the mean behavior estimated as in standard solutions to a Boltzmann transport
equation~\cite{shultis_mc,mcnp}, although the source is
complicated and produces both positive and negative statistical weights; sampling of the
source is detailed in Sec.~\ref{sec:systematic_sampling}.  
It is noted that the exact error in $\tilde{I}^{n+1,(m)}$ (with respect to
Eq.~\eqref{eq:ho_base}) is being estimated with MC;
tallies produce an integral projection of the error onto a LDFE space-angle trial space. 
Volumetric flux tallies over each space-angle element are required to estimate
$\tilde{\epsilon}^{(m)}$, as detailed in Sec.~\ref{sec:tallies}.  
The
space-angle moments of the error, preserved with the representation $\tilde{\epsilon}^{(m)}$, can be added to the
moments of $\tilde{I}^{n+1}(m)$ to produce a more accurate solution.  

The ECMC algorithm iterates on this process as follows:
\begin{enumerate}
    \item Initialize the guess for $\tilde{I}^{n+1,(0)}$ to $\tilde{I}^{n}$ or the
        projection of $\tilde{I}^{n+1}$ from the latest HO solve
\item Compute $r^{(m)}$.
\item Perform a MC simulation to obtain $\tilde{\epsilon}^{(m)} = \B L^{-1} r^{(m)}$
\item Compute a new estimate of the intensity $\tilde I^{n+1,(m+1)} = \tilde I^{n+1,(m)}
+ \tilde\epsilon^{(m)}$
\item Repeat steps 2 -- 4 until desired convergence criteria is achieved. 
\end{enumerate}
Exponential convergence is obtained if the error $\epsilon$ is reduced each batch.  With each batch, a
better estimate of the solution is being used to compute the new residual, decreasing
the magnitude of the MC residual source at each iteration $m$, relative to the solution
$I^{n+1}$.
The initial guess for the angular intensity $I^{n+1,(0)}$ is computed based on the previous solution
for $\tilde{I}^{n}$. This is a critical step in the algorithm; it significantly reduces the required number of
particles per time step because the intensity does not change drastically between time steps in
optically-thick regions.  


\subsection{Projection and Statistical Accuracy of ECMC}

Here, we emphasize the solution $\tilde{I}^{n+1,(m)}$ represents the LDFE projection of the exact Monte Carlo
solution to the transport problem defined by Eq.~\eqref{eq:ho_base}.  The discretization error is in $q$, i.e., the LD spatial
representation of the emission and scattering source and the LDFE space-angle projection $\tilde I^{n}(x,\mu)$.
 The projection of the intensity is in
general far more accurate than a standard finite element solution, e.g., a S$_N$ collocation method in angle.  In typical IMC calculations, the average
energy deposition within a cell is a projection that is computed with a standard path-length volumetric
flux tally; the zeroth moment of the LDFE projection of ${\epsilon}$ is
computed using an equivalent tally, preserving the zeroth moment of the true error.

To see why the true error is being estimated, it is important to note that 
$\B L$ in Eq.~\eqref{eq:err_eq} is the continuous operator.  The MC inverse $\B L^{-1}$ is
a statistical solution method for an integral equation.  The solution to this integral
equation can be shown to provide the analytic inverse of the operator $\B
L$~\cite{shultis_mc,cj_thesis}.  Applying $L^{-1}$ to Eq~\eqref{eq:err_eq} and adding the
result to the previous solution yields the desired moments of the exact solution:
\begin{align}
   \tilde I^{n+1,(m+1)} &= \tilde I^{n+1,(m)} + \tilde\epsilon^{(m)} \\
                  &\simeq  \tilde I^{n+1,(m)} + \B L^{-1} \left(q - \B L \tilde I^{n+1,(m)} \right) \\
                  &\simeq \B L^{-1} q
\end{align}
where the above expression is equal in the limit of an infinite number of histories,
within a single batch.

A MC batch provide a standard MC transport estimate of moments of the error.  Each batch
estimate of the moments of $\epsilon$ has a statistical uncertainty that, with sufficient
sampling, is governed by the standard $1/\sqrt{N}$ convergence rate~\cite{shultis_mc}, for a
particular source $r^{(m)}$, where $N$ is the number of histories performed.  If the statistical estimate of the projection $\tilde\epsilon$ is not sufficiently
accurate, then the iterations would diverge. It is noted that there is statistical correlation across batches because
$I^{n+1,(m+1)}$ and $\epsilon^{(m)}$ are correlated through $I^{n+1,(m)}$ and the MC source $r^{(m)}$.  
A general proof of exponential
convergence for related adaptive MC transport methods is depicted in~\cite{spanier_mc}.  

Because the intensity is saved between time steps, there is correlation that
can not be easily measured.  However, within a batch, the statistical uncertainty in moments of $\epsilon^{(m)}$ can be estimated with the
sample variance of histories, using the standard sample-variance of MC mean
estimators~\cite{shultis_mc}.  This provides a statistical estimate of moments
of the solution estimated in that batch that asymptotically obey the central
limit theorem~\cite{shultis_mc}, conditioned on the previous solution
$I^{n+1,(m)}$.  However, care must be taken with these statistical estimates,
as they do not have the usual MC interpretation of confidence intervals because
of correlations.  Explicitly, if a particular simulation is repeated with
independent sets of random numbers, the sample means will not (on average)
correctly reproduce the confidence interval that the sample variance from the
original simulation estimated.  Additionally, the number of histories within
each batch are likely too low  for the central limit theorem to truly apply, as
they  do not sample the full solution space sufficiently~\cite{mcnp}.  

\subsection{Adaptive Mesh Refinement}

Because the exact angular intensity does not in general lie within the LDFE trial space, the
iterative estimate of the error will eventually stagnate once the error cannot be sufficiently
represented by a given FE mesh.  An adaptive $h-$refinement algorithm has been
implemented that can be used to allow the system to continue converging towards the
exact solution~\cite{jake,ans_2014}. For TRT problems where absorption-reemission physics dominate, the diffusive and slowly varying
regions of the problem require a less refined angular mesh to capture the solution than typical neutronics
problems.  However, greater spatial resolution is needed due to steep spatial
gradients.   
Once error stagnation has occurred (and mesh refinement has reached a maximum level),
additional histories can be performed with a
fixed residual source to estimate the remaining error in the current solution.  Although the remaining error will
converge statistically at a standard $1/\sqrt{N}$ convergence rate, the remaining
error will be much smaller than for a standard MC simulation, producing a much more
efficient solution method overall.

Detailed equations for performing projections between meshes and computing the
residual source on the refined meshes can be found in~\cite{jake}.  At the end
of the ECMC batch, refinement is performed in space-angle cells based on a jump
indicator.  The jump indicator is the magnitude of the different between
$I(x,\mu)$ in adjacent cells, averaged over each edge.  The value of the
largest jump, out of the four edges within a cell, is used as the indicator for
that cell; alternatively, the error could directly be used as an indicator. Based on this indicator, a preset fraction of cells are refined
based on the indicator.  The refinement of a cell is chosen to be symmetric,
with each space-angle cell divided into four equal-sized cells and only one
refinement level difference between adjacent cells is allowed, except for cells
that share an edge across $\mu=0$.  The solution for $\tilde{I}^{n+1}(x,\mu)$
of the batch is projected onto the finer mesh for the next batch. Because the
dimensionality of the sample space has increased, we increase the number of
histories per batch such that the ratio of the number of histories to total
cells is approximately constant for all meshes.  At the end of the last HO
solve in a time step, $\tilde{I}^{n+1}$ is projected back onto the original,
coarsest mesh and stored as $\tilde{I}^{n}$ for the next time step.

\subsection{Negative Values for the Radiation Intensity}
\label{sec:ho_easyfix}

For the HO solver, in cells with a steep gradient, the LDFE trial space can result in
negative values of $\tilde{I}^{n+1}(x,\mu)$, similar to in the LO equations. In
general, in such cells where the trial space cannot accurately represent the solution,
error stagnation will rapidly occur.   More
sophisticated methods for resolving negative values are investigated in
Chapter~\ref{chp:negativities}.  However, because the residual formulation in ECMC allows
for negative weight particles to occur, it is not strictly necessary to treat these cells
specially during each MC batch.  Instead, two simple fixups can be applied: unphysical angular consistency terms can be
modified, or the LDFE projection of the intensity can be modified to be strictly positive
at the end of the MC batch.  To modify angular consistency terms, we determine if
consistency terms lie in the appropriate half space at the end of the HO solve, an
indication that the intensity was negative within that spatial cell.  If any terms are
non-physical, then they are replaced with the corresponding S$_2$-equivalent value, i.e.,
$\mu^{\pm}=\pm 1/\sqrt{3}$.  For the second fixup, we scale the slopes of the solution to
produce a positive representation, as detailed in Sec.~\ref{sec:pos_ldfe}.

\section{Systematic Sampling Algorithm for Residual Source}
\label{sec:systematic_sampling}

The LDFE representation given by Eqs.~\eqref{eq:ld_intens},~\eqref{eq:left_uw},
and~\eqref{eq:right_uw} is substituted into Eq.~\eqref{eq:resid} and evaluated
to produce the residual source for each ECMC batch.  The MC source
$r^{(m)}(x,\mu)$ in Eq.~\eqref{eq:mc_err} consists of volumetric sources and
face sources that are sampled.  The face sources result from the spatial derivative applied to
the discontinuities in the trial space, including a discontinuity at the boundaries for
incoming directions~\cite{jake}.  The source can also produce positive and
negative weight particles.  The probability distribution function (PDF) for
sampling particle coordinates is formed by dividing $r^{(m)}(x,\mu)$ by $\|r^{(m)}(x,\mu)\|_1$,
i.e., the $L_1$ norm over space and angle of the residual.  Particle coordinates (in $x$ and $\mu$)
are sampled from the strictly positive PDF; then, if the residual is negative at the sampled coordinates, the weight of the
particle history is negative. With
the statistical weights of each particles normalized to unity, then the tallies must be multiplied
by $\|r^{(m)}\|_1$ to produce the correct magnitude for moments of error.
  More details on specific equations for evaluating integrals of the
residual for steady-state neutronics problems can be found in~\cite{jake}.  
 
As a method to improve statistical efficiency within a batch, a modified version of the systematic
sampling method~\cite{shultis_mc} (a form of stratified sampling) was implemented for determining the number of
histories sampled from each space-angle cell.  In the systematic sampling algorithm, the
number of particle histories sampled in each space-angle cell is predetermined and
proportional to the integral of the
PDF over that cell.  The goal is to effectively distribute particle histories to regions of
importance, but to sample a preset, minimum number of histories $N_{\min}$ in less probable
regions; this is to limit bad statistics in low probability cells (this is primarily important for adaptively
refined meshes).  However, there is no need to sample histories
from regions in thermal equilibrium, where the probability of a particle being born is on
the order of roundoff.  In most of the simulations performed for this work
$N_{\min}=1$; this choice is made to keep the total number of histories per time
step constant throughout the simulation for comparison to IMC.  

The unmodified probability of a particle being born in cell $ij$ is 
\begin{equation}
    p_{ij} = \frac{\|r^{(m)}\|_{1,{ij}}}{\|r^{(m)}\|_1}
\end{equation}
where $\|r\|_{1,ij}$ is the L$_1$ norm over cell $ij$, including the upwind face and interior
volumetric source.
Thus, the number of
particles in cell $ij$ is 
\begin{equation}
    N_{ij} = 
\left\{\begin{matrix}
    \lfloor(N_bp_{ij})\rceil & N_bp_{ij} > N_{\min}
    \\ 0 & p_{ij} < O(\epsilon_{prec})
\\ N_{\min} & \text{else}
\end{matrix}\right.
\end{equation}
where $N_{\min}$ is the minimum number of histories in significant cells, $N_b$ is the
total number of histories sampled that batch, and
$\epsilon_{prec}$ is on the order of double precision.  
Particle weights must be adjusted to account for
the difference between the number sampled from a particular cell and the original probability
of that element being sampled.  This rounding requires some additional histories
needing to be sampled, or removed, to reach a specific number of histories.  These
modifications are made to the most probable cell

The algorithm for sampling each of the $N_{ij}$ starting histories, from each $ij$ element, is
\begin{enumerate}
    \item Sample random number $\eta\sim U(0,1)$ 
    \begin{enumerate}
        \item If $\eta < \|r^{(m)}_{\text{face}}\|_{1,ij}/\|r^{(m)}\|_{1,ij}$:
            \begin{itemize}
                \item Sample $(x,\mu)$ from $\overline r_{ij,\text{face}}$ face source with
                    rejection sampling
            \end{itemize}
        \item Else:
            \begin{itemize}
                \item Sample $(x,\mu)$ from $\overline r_{ij,\text{int}}$ volumetric source
                    using rejection sampling
            \end{itemize}
    \end{enumerate}
\item Set particle weight to $p_{ij}N_b/N_{ij}$
\end{enumerate}
where $\overline r_{i,\text{face}}$ and $\overline r_{i,\text{int}}$ are the upwind face and
interior residual in cell $ij$.

The residual gives a good indication of where
histories are most likely to contribute to the error, particularly in optically
thick cells where particles do not transport long distances. Systematic sampling is a
variance reduction technique that reduces the variance of the function, i.e., the residual, being sampled~\cite{shultis_mc}.  Thus, we expect
variance to be reduced by more efficiently sampling the residual in optically thick cells.  In thin
cells, where particles transport farther, this sampling procedure does not guarantee less variance
overall. 



\section{Continuous Weight Deposition Tallies}
\label{sec:tallies}

During a MC batch, moments of the error are tallied.  The necessary moments of the error are
defined analogously to Eq.'s~\eqref{eq:Imoms}--\eqref{eq:Imoms2}.  
The tallies are evaluated by weighting the particle density with the appropriate
basis function and integrating along the history path through the cell.  The LDFE
representation results in local tallies where only particles entering a particular cell
contribute to that cell's estimators.  For the cell average, the $n$-th
particle that enters the cell $ij$ makes the contribution, or \emph{score},
\begin{equation}\label{eq:avg_tal}
   \epsilon^n_{a,ij} = \frac{1}{h_ih_j} \int\limits_{s^n_o}^{s^n_f}  w^n(x,\mu) \dd s,
\end{equation}
where $s_o^n$ and $s_f^n$ are the beginning and end of the $n$-th particle track in the cell and $w(x,\mu)$ is
the weight of the error particle in the MC simulation. 

As in~\cite{park}, because we are solving a pure absorber problem with Monte Carlo, we will allow
particles to stream without absorption to reduce statistical 
variance in the tallies.  The weight of particles is reduced deterministically along
the path as they stream, with no need to sample a path length. Histories are allowed to stream in this manner for 6 mean free paths (mfp)
before switching to analog path length sampling; this limits the tracking of very small weight histories. The choice of 6 mfp allows particles to 
continuously deposit weight until they reach 0.25\% of their original weight.  Path lengths are tracked in terms of mfp, so there is no need to resample at material
interfaces.

Weight is attenuated exponentially, i.e., $w(x,\mu)\propto
\exp(-\sigma_{t}^{\text{eff}}|x/\mu|)$, where for the time-discretized equations
$\sigma_{t}^{\text{eff}}=\sigma_t + 1/(c\Dt)$. Substitution of the weight representation into
Eq.~\eqref{eq:avg_tal} produces the result
\begin{equation}
    \epsilon^n_{a,ij} = \frac{w(x_0,\mu)}{\sigma_{t}^{\text{eff}} h_i h_j} \left(1 -
    e^{-\sigma_{t}^{\text{eff}}s^n}\right).
\end{equation}
Here, $w(x_0,\mu)$ is statistical weight of the particle at the start of the path and $s^n$ is the
length of the track. The contribution of a
particle track to $\epsilon_x$ is given by
\begin{equation}
    \epsilon^n_{x,ij} = \frac{w(x_0,\mu)}{h_i^2h_j \sigma_{t}^{\text{eff}}} \left[x_0 - x_f e^{-\sigma_{t}^{\text{eff}} s^n}
        + \left(\frac{\mu}{\sigma_{t}^{\text{eff}}} - x_i \right)\left(1-e^{-\sigma_{t}^{\text{eff}} s^n}\right),
    \right]
\end{equation}
where $x_0$ and $x_f$ are the beginning and ending $x$ coordinates of the $n$-th
path.  The contribution to the first moment in $\mu$ is 
\begin{equation}
    \epsilon^n_{\mu,ij} = \frac{w(x_0,\mu)}{h_{j}^2h_i\sigma_{t}^{\text{eff}}}\left(\mu -
    \mu_j\right) \left(1 - e^{-\sigma_{t}^{\text{eff}}s^n}\right),
\end{equation}
where the particle $x$-direction cosine $\mu$ does not change, because it is a pure-absorber simulation.
The unbiased estimators for the moments of the error, e.g., $\hat \epsilon_{a,ij}$, are simply the
average score from all histories:
\begin{equation}
    \hat\epsilon_{a,ij}^{(m)}  = \frac{1}{N_b} \sum\limits_{n=1}^{N_b} \epsilon^n_{a,ij}
\end{equation}
where $N_b$ is the number of particle histories performed within that batch.


\subsection{Face Tallies and correction near $\mu=0$}
\label{sec:face_tallies}

Face-averaged estimators of $\epsilon(x,\mu)$ are required to compute the outflow for
estimating the spatial closure discussed in Sec.~\ref{sec:spat_clos}. The standard face-based
tallies~\cite{shultis_mc,favorite_faces} are used.  Tallies are weighted by
the appropriate basis functions to compute a linear FE projection in $\mu$ at each face.  The
tally score, for the angular-averaged error $\epsilon_{a,i}$ is defined as
\begin{equation}
    \hat \epsilon_{a,i\pm1/2,j} = \frac{1}{N} \sum_{m=1}^{N_{i\pm1/2,j}}
    \frac{w_m(x_{i\pm1/2},\mu)}{h_{\mu} |\mu|},
\end{equation}
where $N$ is the number of histories performed and $N_{i\pm1/2,j}$ is the number of histories
that crossed the surface $i\pm1/2$, in the $j$ angular element.   For the first
moment, the tally is
\begin{equation}\label{eq:face_mutally}
    \hat \epsilon_{\mu,i\pm1/2,j} = \frac{1}{N} \sum_{m=1}^{N_{i+1/2,j}} 
    6\left(\frac{\mu-\mu_j}{h_\mu}\right) \frac{w_m(x_{i\pm1/2},\mu)}{|\mu| h_{\mu}}.
\end{equation}
For positive and negative directions, solutions are only tallied
on the $x_{i+1/2}$ and $x_{i-1/2}$ faces, respectively. Particles are only tallied after leaving
a cell, and, as discussed in Section~\ref{sec:ldd_mc}, particles born on a surface do not contribute
to the tally of that surface.

Near $\mu=0$, particles can contribute large scores to the zeroth angular moment that lead to large and
unbounded variances~\cite{favorite_faces}.  To avoid large variances, we have applied the standard fixup~\cite{mcnp,favorite_faces}.  
For $|\mu|$ below some small value $\mu_{cut}$, 
particles contribute the expected score over the range $(0,|\mu_{cut}|)$ for an
approximate isotropic particle density. Thus, scores in this range have no variance, but are biased
for non-isotropic intensities.  For all results in this work $\mu_{cut}=0.01$.  Assuming
an isotropic particle density $I_0$, the average of
$1/\mu$, for positive $\mu$, is
\begin{equation}
    \overline{1/\mu} = \frac{\displaystyle \int_0^{\mu_{cut}}\frac{1}{\mu} I_0 \,\dd
\mu}{\displaystyle \int_0^{\mu_{cut}} I_0\, \dd \mu} =
    \frac{2}{\mu_{cut}}.
\end{equation}
For negative $\mu$, $\overline{1/\mu}=-2/\mu_{cut}$.
All particles in the range $(0,|\mu_{cut}|)$ contribute the expected score by evaluating
the appropriate estimator at $\pm\mu = \pm2/\mu_{cut}$.  It is noted that the first angular moment would be well behaved, but it is inconsistent to only modify the zeroth 
moment in the $I_\mu$ estimators. Additionally, assuming an isotropic intensity near $\mu=0$ helps to limit
the first $\mu$ moment, where the LD trial space often cannot resolve the solution anyways.



\section{ECMC Solution with Linear Doubly-Discontinuous FE Trial Space}
\label{sec:ldd_mc}

In this section, the ECMC method is extended to a spatially linear, doubly-discontinuous
(LDD) trial space.   
This extension is necessary for computing the HO spatial closure for
the LO equations discussed in Sec.~\ref{sec:spat_clos}.  To incorporate a projection of
the MC solution at faces, a second discontinuity is
introduced into the trial space. 

 The LDD trial space is demonstrated for the $x$ variable in
Fig.~\ref{fig:ldd_space}.   For the HO solver, the LDD trial space is the same as the LDFE
space-angle trial space, except for an extra discontinuity in space at the outflow face.
The solution at faces is linear in angle over the angular width of each $x$-$\mu$ cell.
The LDD representation for cell $ij$ is
\begin{equation}\label{eq:ldd_I}
    \tilde{I}_{ij}(x,\mu) = \left \{ \begin{array}{cl}
        I_{a,i-1/2,j}+\frac{2}{h_j}I_{\mu,i-1/2,j}\left(\mu-\mu_j\right) &
        x=x_{i-1/2} \\
I_{a,ij} + \frac{2}{h_i}I_{x,ij}\left(x-x_i\right) +
\frac{2}{h_j}I_{\mu,ij}\left(\mu-\mu_j\right) & x_{i-1/2} < x < x_{i+1/2}  \\
    I_{a,i+1/2,j}+\frac{2}{h_j}I_{\mu,i+1/2,j}\left(\mu-\mu_j\right) &   x=x_{i+1/2}  
\end{array} \right.,
\end{equation}
for $\mu_{j-1/2} \leq \mu \leq \mu_{j+1/2}$.  The face-tallied quantities $I_{a,i\pm1/2}$ and $I_{\mu,i\pm1/2}$ are shared
between adjacent cells, so the expression is the same for positive and negative $\mu$.
The linear representation at faces preserves all angular moments of the intensity needed for the spatial closure and
face-averaged consistency terms.  

The residual source and process of estimating moments of
the error on the interior of space-angle cells is unchanged.  The process of estimating
the solution on the outgoing face requires tallying the error when particles leave a
cell, using the face-averaged tallies discussed in Section~\ref{sec:face_tallies}.  
Face-averaged consistency terms are directly evaluated using $\tilde
I(x_{i+1/2},\mu)$ evaluated at the face of each coarse mesh cell.   

The inclusion of the outflow discontinuity in space has a minimal effect on the treatment of the
residual source.
Applying $L$ to the LDD intensity given by Eq.~\eqref{eq:ldd_I}, results in two $\delta$ functions at each interior face.
For \emph{positive flow}, at a face $x_{i+1/2}$, the face portion of the residual is defined as
\begin{align}
    \label{eq:res_face}
    \rface(x_{i+1/2}) &= -\mu \pderiv{\tilde I^{(m)}}{x}\bigg|_{x=x_{i+1/2}}\\
    &= \rface(x_{i+1/2}^-)\delta^-(x - x_{i+1/2}) + \rface(x_{i+1/2}^+)\delta^+(x - x_{i+1/2}) 
\end{align}
where
\begin{align}
    \rface(x_{i+1/2}^-) &= -\mu\left( \tilde I^{(m)}(x_{i+1/2},\mu) - \tilde I^{(m)}(x_{i+1/2}^-,\mu)
           \right)\\
    \rface(x_{i+1/2}^+) &= -\mu\left( \tilde I^{(m)}(x_{i+1/2}^+,\mu) -
           \tilde I^{(m)}(x_{i+1/2},\mu)
           \right).
\end{align}
Here, $I^{(m)}(x_{i+1/2},\mu)$ is the face-estimated solution at $x_{i+1/2}$ and
$I^{(m)}(x_{i+1/2}^+)$ and $I^{(m)}(x_{i+1/2}^-)$ are the LDFE solution
\emph{extrapolated} to $x_{i+1/2}$ from the $x$ cell $i+1$ and cell $i$, respectively; all
three terms are linear in
$\mu$ over $\mu_{j-1/2} \leq \mu \leq \mu_{j+1/2}$.  Particles sampled from the
two $\delta$-functions have the same starting location.  The only difference is, for
positive $\mu$, only the particles sampled from $\rface(x^-_{i+1/2})$ will contribute to the face
tally at $x_{i+1/2}$; the opposite is true for negative $\mu$.  

To reduce variance, we do not sample the two $\delta$ functions independently.
%or score contributions to the outflow face from the interior face source. 
Instead, the
two $\delta$-functions are combined into a single face source in each element\footnote{The combination of the two $\delta$-functions produces the same residual source as the
original LD trial-space residual.},
and particles do \emph{not} score at the face from which they are sampled.  To account for the
untallied error, we add the analytic
contribution to $\epsilon_{i+1/2}$ from $r_{\text{face}}(x_{i+1/2}^-)$, at the end of
each batch.  This analytic contribution to the error at faces is derived in Sec.~\ref{sec:face_err_deriv}. 
The update for $I(x_{i+1/2},\mu)$ becomes
\begin{align}
   \tilde I^{(m+1)}(x_{i+1/2},\mu)  &= \tilde I^{(m)}(x_{i+1/2}^-,\mu) +
   \epsilon^{(m)}(x_{i+1/2},\mu) & \mu > 0 \\
   \tilde I^{(m+1)}(x_{i+1/2},\mu)  &= \tilde I^{(m)}(x_{i+1/2}^+,\mu) +
   \epsilon^{(m)}(x_{i+1/2},\mu) & \mu < 0
\end{align}
This result has the serendipitous effect that the estimation of the solution on a face depends only on
the previous interior solutions $\tilde I^{(m)}(x_{i+1/2}^-,\mu)$ and $\tilde
I^{(m)}(x_{i-1/2}^+,\mu)$ and not the previous face value 
$\tilde I^{(m)}(x_{i+1/2},\mu)$. This has an additional benefit that the face values can
be estimated at any chosen batch, in particular cells.  For this work, the solution is
estimated in all cells in the LDD trial space.


