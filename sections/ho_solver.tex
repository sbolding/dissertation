
\chapter{\uppercase {The High-Order Exponentially-Convergent Monte Carlo Solver}}

\section{The ECMC High Order Solver}

The transport equation to be solved by the HO solver is
\begin{equation}\label{eq:ho_base}
\mu \pderiv{I^{n+1,k+1/2}}{x} + \left(\sigma_t^k + \frac{1}{c \Delta t }\right)
I^{n+1,k+1/2}
= \frac{\sigma_s}{2} \phi^{n+1,k} +\frac{1}{2} \left(\sigma_a^k a c T^4
\right)^{n+1,k} + \frac{\tilde I^n}{c\Delta t} 
\end{equation}
where the superscript $k$ represents the outer HOLO iteration index.  Material property indices will be
suppressed from now on.  Here, $k+1/2$ denotes the
ECMC solution within outer HOLO iteration $k$, whereas $k$ and $k+1$ represent successive LO
solves. The sources at $k$ in Eq.~\eqref{eq:ho_base} are estimated by the previous LO solution. Cross sections are
evaluated at $T^{n+1,k}$.  As all sources on the right side of the equation are known,
this defines a fixed-source, pure absorber transport problem.  We will solve
this equation using ECMC.  A more detailed description of the
ECMC method can be found in~\cite{jake}, but a brief overview is given here.  A general proof of exponential convergence for related adaptive MC transport methods with a different formulation is depicted in~\cite{spanier_mc}.

 In operator notation, Eq.~\eqref{eq:ho_base} can be written as
\begin{equation}\label{te_oper}
\B L^k I^{n+1,k+1/2}  = q^{k}
\end{equation}
where $I^{n+1,k+1/2}$ is the transport solution of the angular intensity based on the
$k$-th LO estimate of $q^k$.
The linear operator $\B L^k$ is the continuous streaming plus
removal operator defined by the left hand
side of Eq.~\eqref{ho_trans}.
The $m$-th approximate LDFE solution to Eq.~\eqref{te_oper} ($m$ is the index of inner HO
batches) is represented as
$\tilde{I}^{n+1,(m)}$.    
The $m$-th residual is defined as $r^{(m)} = q - \B L^k\tilde{I}^{n+1,(m)}.$ 
For reference, the residual at iteration $m$ in the HO solve
is
\begin{equation}\label{eq:resid}
r^{(m),k+1/2} = \frac{\sigma_s}{2} \phi^{n+1,k} +\frac{1}{2} \left(\sigma_a a c T^4
\right)^{n+1,k} + \frac{\tilde{I}^n}{c \Delta t } -
\left(\mu \pderiv{\tilde{I}^{n+1,k+1/2}}{x} +
\left(\sigma_t + \frac{1}{c \Delta t }\right) \tilde{I}^{n+1,k+1/2}\right)^{(m)}
\end{equation}
where the $k$ terms are LD in space on the coarsest mesh and are not recalculated at any point during
the HO solve. The functional form of $\tilde{I}^n$ is defined from the final HO
solution of the previous time step.  

Addition of $\B L I^{n+1} - q=0$ to the residual equation 
and manipulation of the result yields the error equation
\begin{equation}\label{eq:err_eq}
    \B L (I^{n+1} - \tilde{I}^{n+1,(m)}) = \B L {\epsilon}^{(m)} = r^{(m)}
\end{equation}
where $I^{n+1}$ is the exact solution and ${\epsilon}^{(m)}$ is the true error in
$\tilde{I}^{n+1,(m)}$. 
We have suppressed the HOLO iteration indices because the LO estimated $q^{k}$ and $\B L^{k}$ remain constant over the entire HO solve.
The $\B L$ operator in the above equation is inverted yielding
the Monte Carlo LDFE projection of the error in $\tilde{I}^{n+1,(m)}$, i.e., 
\begin{equation}\label{eq:mc_err}
\tilde{\epsilon}^{(m)} = \B L^{-1} r^{(m)}
\end{equation}
where $\B L^{-1}$ is the Monte Carlo inversion of the streaming and removal operator.  
This inversion is strictly a standard Monte Carlo simulation.   It is noted that the exact
error in $\tilde{I}^{n+1,(m)}$ (with respect to Eq.~\eqref{eq:ho_base}) is being estimated with MC;
%in Because $\B L$ in Eq.~\eqref{eq:err_eq} is the continous operator and $\B
%L^{-1}$ represents the analytic inverse of $\B L$~\cite{shultis_mc}, the exact error
tallies produce a projection of the error onto a LDFE space-angle trial space. The space-angle
moments of the error computed as $\tilde{\epsilon}^{(m)}$ can be added to the
moments of $\tilde{I}^{n+1}(m)$ to produce a more accurate solution.  


Here, we emphasize the solution $\tilde{I}^{n+1,(m)}$ represents the LDFE projection of the exact Monte Carlo
solution to the transport problem defined by Eq.~\eqref{eq:ho_base}.  The discretization error is in $q$, i.e., the LD spatial
representation of the emission and scattering source and the LDFE space-angle projection $\tilde I^{n}(x,\mu)$.
 The projection of the intensity is in
general far more accurate than a standard finite element solution, e.g., a S$_N$ collocation method in angle.  In typical IMC calculations, the average
energy deposition within a cell is computed using a standard path-length volumetric
flux tally; the zeroth moment of the LDFE projection of ${\epsilon}$ is
computed using an equivalent tally, preserving the zeroth moment of the true error.

Volumetric flux tallies over each space-angle element are required to estimate
$\tilde{\epsilon}^{(m)}$.  The LD approximation in space is used to relate the
outflow within a cell to the volumetric moments, eliminating the need for
face-averaged tallies.  The procedure for representing the solution, sampling with negative and
positive weight particles, and tally
definitions are given in Appendix~\ref{app:tallies}.

The ECMC algorithm is
\begin{enumerate}
    \item Initialize the guess for $\tilde{I}^{n+1,(0)}$ to $\tilde{I}^{n}$ or the
        projection of $\tilde{I}^{n+1}$ from the latest HO solve
\item Compute $r^{(m)}$.
\item Perform a MC simulation to obtain $\tilde{\epsilon}^{(m)} = \B L^{-1} r^{(m)}$
\item Compute a new estimate of the intensity $\tilde I^{n+1,(m+1)} = \tilde I^{n+1,(m)}
+ \tilde\epsilon^{(m)}$
\item Repeat steps 2 -- 4 until desired convergence criteria is achieved. 
\end{enumerate}
The initial guess for the angular intensity $I^{n+1,(0)}$ is computed based on the previous solution
for $\tilde{I}^{n}$. This is a critical step in the algorithm; it significantly reduces the required number of
particles per time step because the intensity does not change drastically between time steps in
optically-thick regions.  It is noted that the ECMC batch (steps 1-4 of the
algorithm) results in essentially the same estimate of the solution as the residual
formulation used in~\cite{rmc}.  The primary difference is that our method uses an LDFE trial
space and iterates on the solution estimate by recomputing the residual.

Exponential convergence is obtained if the error $\epsilon$ is reduced each batch.  With each batch, a
better estimate of the solution is being used to compute the new residual, decreasing
the magnitude of the MC residual source at each iteration $m$, relative to the solution
$I^{n+1}$.  Each MC
estimate of the moments of $\epsilon$ still has a statistical uncertainty that is
governed by the standard $1/\sqrt{N}$ convergence rate~\cite{shultis_mc}, for a
particular source $r^{(m)}$, where $N$ is the number of histories performed.  If the statistical estimate of the projection $\tilde\epsilon$ is not sufficiently
accurate, then the iterations would diverge. It is noted that there is statistical correlation across batches because
$I^{n+1,(m+1)}$ and $\epsilon^{(m)}$ are correlated through $I^{n+1,(m)}$ and the MC source $r^{(m)}$.  
%Although th
%variance in tallies of $\epsilon^{(m)}$ can be estimated with the sample variance of
%histories, the variance in the moments of $I^{n+1,(m+1)}$ cannot be easily
%estimated due to the correlation between $I^{n+1,(m)}$ and the source
%$r^{(m)}$.

Because the exact angular intensity does not in general lie within the LDFE trial space, the
iterative estimate of the error will eventually stagnate once the error cannot be sufficiently
represented by a given FE mesh.  An adaptive $h-$refinement algorithm has been
implemented that can be used to allow the system to continue converging towards the
exact solution~\cite{jake,ans_2014}. For TRT problems where absorption-reemission physics dominate, the diffusive and slowly varying
regions of the problem require a less refined angular mesh to capture the solution than typical neutronics
problems.  However, greater spatial resolution is needed due to steep spatial
gradients.   
Once error stagnation has occurred (and mesh refinement has reached a maximum level),
additional histories can be performed with a
fixed residual source to estimate the remaining error in the current solution.  Although the remaining error will
converge statistically at a standard $1/\sqrt{N}$ convergence rate, the remaining
error will be much smaller than for a standard MC simulation, producing a much more
efficient solution method overall.

For the HO solver, in cells near the radiation wavefront, the LDFE trial space results in
negative values in $\tilde{I}^{n+1}(x,\mu)$, similar to the LO solver.  Because the residual formulation in ECMC allows for negative weight
particles to occur, currently we do not treat these cells specially.  We detect if
the consistency terms lie in the appropriate half space at the end of the HO solve,
an indication that the intensity was negative within that cell.  If the terms are non-physical, then
they are replaced with the corresponding S$_2$-equivalent value. In general,
in such cells where the trial space cannot accurately represent the solution, error stagnation will
rapidly occur. 

\section{MC solution with LDD trial space}
\label{sec:ldd_mc}

The inclusion of the outflow discontinuity has a minimal effect on the treatment of the
residual source. The residual source and process of estimating moments of
the error on the interior of a space-angle cell is unchanged.  The process of estimating
the solution on the outgoing face requires tallying the solution when particles leave a
cell. The tallying process is discussed later in Section~\ref{sec:face_tallies}.  

Applying $L$ to the LDD trial space, as shown in Fig.~\ref{fig:ldd}, results in two $\delta$ functions at each interior face.
For positive flow, at a face $x_{i+1/2}$, the face portion of the residual is defined as
\begin{align}
    \label{eq:res_face}
    \rface(x_{i+1/2}) &= -\mu \pderiv{\tilde I^{(m)}}{x}\big|_{x_{i+1/2}}\\
    &= \rface(x_{i+1/2}^-)\delta^-(x - x_{i+1/2}) + \rface(x_{i+1/2}^+)\delta^+(x - x_{i+1/2}) 
\end{align}
where
\begin{align}
    \rface(x_{i+1/2}^-) &= -\mu\left( \tilde I^{(m)}(x_{i+1/2},\mu) - \tilde I^{(m)}(x_{i+1/2}^-,\mu)
           \right)\\
    \rface(x_{i+1/2}^+) &= -\mu\left( \tilde I^{(m)}(x_{i+1/2}^+,\mu) -
           \tilde I^{(m)}(x_{i+1/2},\mu)
           \right).
\end{align}
Here, $I^{(m)}(x_{i+1/2}^+)$ and $I^{(m)}(x_{i+1/2}^-)$ are the LD solution extrapolated to $x_{i+1/2}$ from the
$x$ cell $i$ and cell $i+1$, respectively.
Particles sampled from the two $\delta$-functions have the same starting location.  The
only difference is, for positive $\mu$,  particles sampled from $\rface(x^-_{i+1/2})$ will
contribute to the face tally at $x_{i+1/2}$; the opposite is true for negative $\mu$.

To reduce variance, we do not sample the two $\delta$ functions independently.
%or score contributions to the outflow face from the interior face source. 
Instead, we combine the
two $\delta$-functions into a single face source,
do not score particles at the face from which they are sampled.  To account for the
untallied error, we add the analytic
contribution to the error from the face source to the corresponding face at the end of a batch.
It is noted the combination of the two $\delta$-functions produces the same residual source as the
original LD residual.

Define the additional error contribution 
from the face sources at $x_{i+1/2}$ as $\dep$.  This additional error is tallied
everywhere by MC, except for at $x_{i+1/2}$.  The transport equation satisfied by $\dep$, for positive
$\mu$, with effective total cross 
section $\hat \sigma_t$, is
\begin{equation}
    \label{eq:ho_face}
    \mu \pderiv{\dep}{x} + \hat\sigma_t \dep = \rface(x_{i+1/2}^-)\delta^-(x - x_{i+1/2}) + \rface(x_{i+1/2}^+)\delta^+(x - x_{i+1/2}) 
\end{equation}
This equation is integrated from $x_{i+1/2}-\alpha$ to $x_{i+1/2}$ to produce
\begin{multline}
    \mu\dep(x_{i+1/2},\mu) - \mu\dep(x_{i+1/2}-\alpha,\mu)  + \int\limits_{x_{i+1/2}-\alpha}^0 
    \hat \sigma_t \dep \dd x  \\ =  \rface(x_{i+1/2}^-) +
        \int\limits_{x_{i+1/2}-\alpha}^0\rface(x_{i+1/2}^+)\delta^+(x - x_{i+1/2}) \dd x.
\end{multline}
The integral on the right side of the equation is zero because $\delta^+(x-x_{i+1/2})$ is
zero for $(-\infty,x_{i+1/2}]$.  The limit of the above equation is taken as $\alpha\to0$, i.e.,
\begin{multline}
    \lim_{\alpha\to0}\left( \mu\dep(x_{i+1/2},\mu) - \mu\dep(x_{i+1/2}-\alpha,\mu)  + \int\limits_{x_{i+1/2}-\alpha}^0 
    \hat \sigma_t \dep \dd x \right)  = \lim_{\alpha\to0} \rface(x_{i+1/2}^-) 
\end{multline}
The integral goes to zero because $\dep$ is smooth on the interior of the cell, and
$\mu\dep(x_{i+1/2}-\alpha,\mu)$ goes to zero because there is no source upstream of
$x_{i+1/2}^-$. Thus, the final solution is
\begin{equation}
    \dep(x_{i+1/2},\mu) = \frac{\rface(x_{i+1/2}^-)}{\mu} = 
     \tilde I^{(m)}(x_{i+1/2}^-,\mu) - \tilde I^{(m)}(x_{i+1/2},\mu)
.
\end{equation}
The update for $I(x_{i+1/2},\mu)$ is 
\begin{align}
   \tilde I^{(m+1)}(x_{i+1/2},\mu) &= \tilde I^{(m)}(x_{i+1/2},\mu) + \epsilon^{(m)}(x_{i+1/2},\mu) +
    \dep(x_{i+1/2},\mu) \\ 
        &= \tilde I^{(m)}(x_{i+1/2}^-,\mu) + \epsilon^{(m)}(x_{i+1/2},\mu).
\end{align}
This result has the peculiar effect that the estimation of the solution on a face depends only on
the interior solution $\tilde I^{(m)}(x_{i+1/2}^-,\mu)$ and not the previous face value 
$\tilde I^{(m)}(x_{i+1/2},\mu)$. This could be used to only estimate
face values in particular cells, at any chosen batch.



\section{Implementation of ECMC finite-element space, tallies, and residual sampling}
\label{app:tallies}

The ECMC solver uses a finite element representation in space and angle. On the
interior of the cell with the $i$-th spatial index and $j$-th angular index, the linear representation is defined as
\begin{equation*}
    \tilde I(x,\mu) = I_{a,ij} + \frac{2}{h_x}I_{x,ij}\left(x-x_i\right) +
    \frac{2}{h_\mu}I_{\mu,ij}\left(\mu-\mu_j\right), \quad x_\il <  x < x_\ir,\quad
     \mu_\jl \leq \mu \leq \mu_\jr
\end{equation*}
The spatial cell width is $h_x$, the angular width is
$h_\mu$, the center of the cell is $(x_i,\mu_j)$, and
\begin{align}\label{app1}
    I_{a,ij} &= \frac{1}{h_x h_\mu} \iint\limits_{\mathcal{D}} I(x,\mu)\, \dd x \dd \mu \\
    I_{x,ij} &= \frac{6}{h_xh_\mu}\iint\limits_{\mathcal{D}} \left(\frac{x - x_i}{h_{x}}\right)
    I(x,\mu)\, \dd x \dd \mu \\ \label{app2}
    I_{\mu,ij} &= \frac{6}{h_xh_\mu}\iint\limits_{\mathcal{D}}
     \left(\frac{\mu - \mu_j}{h_{\mu}}\right)
    I(x,\mu)\, \dd x \dd \mu,
\end{align}
where $\mathcal{D}: x_\il \leq  x \leq  x_\ir \times \mu_\jl \leq \mu \leq \mu_\jr$.
%$I_a$ is the cell average intensity, and $I_\mu$ and $I_x$ define the
%the first moment in $\mu$ and $x$ of the intensity, respectively. 
Standard upwinding in space is used to
define $I(\mu)$ on incoming faces. 

This representation can directly be plugged into
Eq.~\eqref{eq:resid} and evaluated to produce the residual source in the ECMC HO transport
problem.  The MC source $r^{(m)}(x,\mu)$ in Eq.~\eqref{eq:mc_err}
consists of both face and volumetric sources and can produce positive and
negative weight particles.  The distribution for sampling particle coordinates, in space and angle, is based on the $L_1$
norm over space and angle of the residual~\cite{jake}.  A particular cell volume or face 
is sampled, and then rejection sampling~\cite{shultis_mc} is used to sample from
the appropriate distribution on the face or interior of the space-angle cell.  If the
residual is negative at the sampled coordinates, the weight of the particle history is negative.

During a MC batch, moments of the error are tallied.  The necessary moments of the error are
defined analogously to Eq.'s~\eqref{app1}--\eqref{app2}.
The tallies are evaluated by weighting the particle density with the appropriate
basis function and integrating along the history path through the cell.  For the cell average, the $n$-th
particle makes the contribution
\begin{equation}
   \epsilon^n_{a,ij} = \frac{1}{h_xh_\mu} \int\limits_{s^n_o}^{s^n_f}  w^n(x,\mu) \dd s,
\end{equation}
where $s_o^n$ and $s_f^n$ are the beginning and end of the $n$-th particle track in the cell and $w(x,\mu)$ is
the weight of the error particle in the MC simulation.  Weight is attenuated exponentially, i.e., $w(x,\mu)\propto
\exp(-\sigma_t|x/\mu|)$.
Substitution of the exponential attenuation of the weight produces the result
\begin{equation}
    \epsilon^n_{a,ij} = \frac{w(x_0,\mu)}{\sigma_t h_x h_\mu} \left(1 -
    e^{-\sigma_ts^n}\right).
\end{equation}
Here, $w(x_0,\mu)$ is the particle weight at the start of the path and $s^n$ is the
length of the track. The contribution of a
particle track to $\epsilon_x$ is given by
\begin{equation}
    \epsilon^n_{x,ij} = \frac{w(x_0,\mu)}{h_x^2h_\mu \sigma_t} \left[x_0 - x_f e^{-\sigma_t s^n}
        + \left(\frac{\mu}{\sigma_t} - x_i \right)\left(1-e^{-\sigma_t s^n}\right),
    \right]
\end{equation}
where $x_0$ and $x_f$ are the beginning and ending $x$ coordinates of the $n$-th
path.  The contribution to the first moment in $\mu$ is 
\begin{equation}
    \epsilon^n_{\mu,ij} = \frac{w(x_0,\mu)}{h_{\mu}^2h_x\sigma_t}\left(\mu -
    \mu_j\right) \left(1 - e^{-\sigma_ts^n}\right),
\end{equation}
where the particle $x$-direction cosine $\mu$ does not change because it is a pure-absorber simulation.
Finally, the moments of the error are simply the average contribution of all particles.

\section{Adaptive Mesh Refinement}
\label{app:refinement}
This section describes the adaptive refinement strategy for the ECMC algorithm.
Detailed equations for performing projections between meshes and computing the residual source on
the refined meshes can be found in~\cite{jake}.  At the end of the ECMC batch,
refinement is performed in space-angle cells based on a jump indicator.  The jump
indicator is the magnitude of the different between $I(x,\mu)$ in adjacent cells,
averaged over each edge.  The value of the largest jump, out of the four edges within a
cell, is used as the
indicator for that cell.  Based on this indicator, the 20\% of cells with the largest jump are
refined.  Future work will explore simply using $\epsilon$ to indicate refinement,
rather than the jump error.  The refinement of a cell is chosen to be symmetric, with each space-angle cell divided into four
equal-sized cells.  The solution for $\tilde{I}^{n+1}(x,\mu)$ of the batch is projected onto
the finer mesh for the next batch. Because the dimensionality of the sample space has
increased, we increase the number of histories per batch s.t. the ratio of the number
of histories to total cells is approximately constant for all meshes.  At the end of the last HO solve in a time step,
$\tilde{I}^{n+1}$ is projected back onto the original, coarsest mesh and stored as
$\tilde{I}^{n}$ for the next time step.



\subsection{Continuous Weight Deposition Tallies}


As in~\cite{park}, because we are solving a pure absorber problem with Monte Carlo, we will allow
particles to stream without absorption to reduce statistical 
variance in the tallies.  The weight of particles is reduced deterministically along
the path as they stream, with no need to sample a path length.  Because particles are exponentially attenuated, the normalized weight is
adjusted as $w(x,\mu) = w(x_0,\mu)\exp(-\sigma_t|(x-x_0)/\mu|)$, where $x_0$ is the starting location of the path.  The tallies account
for the continuously changing weight, as given in Appendix~\ref{app:tallies}. Histories are allowed to stream in this manner for 6 mean free paths (mfp))
before switching to analog path length sampling; this limits the tracking of very small weight histories. The choice of 6 mfp allows particles to 
continuously deposit weight until they reach 0.25\% of their original weight.  Path lengths are tracked in terms of mfp, so there is no need to resample at material
interfaces.

\subsection{Modified Systematic Sampling Algorithm}
\label{sec:systematic_sampling}

As another way to improve efficiency, a modified systematic sampling
method~\cite{shultis_mc} was used for determining source particle locations.  The goal is
to effectively distribute particle histories to regions of importance, but to sample a
sufficient number of histories in less probable regions to prevent large statistical
noise.  However, there is no need to sample histories in regions in thermal equilibrium.
The residual gives a good indication of where histories are most likely to contribute to
the error, particularly in optically thick cells where particles do not transport long
distances.   In
the sampling algorithm the number of particle histories sampled in each space-angle cell
is predetermined and proportional to the magnitude of the residual, including face and
volumetric sources, within that cell.  Then, for the predetermined number of histories
within a cell, the source location is randomly sampled according to the residual source
distribution of that cell.  In cells where the relative magnitude of the residual is on the order of roundoff no particle histories are sampled. In these 
regions the problem is remaining in equilibrium and the solution is known exactly.  For
cells that are significant, but have a predetermined number of histories below some preset
minimum $N_{min}$, the number of histories sampled in that cell is set to $N_{min}$. This
is to limit bad statistics in low probability cells (this would be important for
adaptively refined meshes).  In the simulations performed for this work $N_{min}=1$.  This
choice was made to keep the total number of histories per time step constant throughout
the simulation for comparison to IMC. 

%The unmodified probability of a particle being born in cell $j$ is 
%\begin{equation}
%p_j = \frac{||r^{(m)}_j||}{||r^{(m)}||}
%\end{equation}
%Thus, the number of
%particles in cell $j$ is 
%\begin{equation}
%N_j = 
%\left\{\begin{matrix}
% \lfloor(Np_j)\rfloor, & Np_j > N_{\min}
%\\ 0, & \frac{p_j}{1/N_c} < p_{cut}
%\\ N_{min}, & \text{else}
%\end{matrix}\right.
%\end{equation}
%where $N_{\min}$ is the minimum number of histories in significant cells, $N_c$  is the number of cells, and $p_{cut}$ is the chosen relative probability cutoff.
 %This is done by first filling the cells with $N_{min}$ histories and distributing the remaining number of histories proportional to $p_j$.

